# DP-Data-Pipeline
Camada de Engenharia de Dados para Privacidade Diferencial
## ğŸ“Œ VisÃ£o Geral

Este repositÃ³rio contÃ©m o sistema intermediÃ¡rio de engenharia de dados do projeto IC Privacidade.
Seu papel Ã© realizar a extraÃ§Ã£o, preparaÃ§Ã£o e privatizaÃ§Ã£o de dados provenientes de um sistema transacional de Recursos Humanos, aplicando Privacidade Diferencial (DP) de forma controlada, versionada e reproduzÃ­vel.

O pipeline foi projetado para isolar a aplicaÃ§Ã£o da privacidade diferencial como variÃ¡vel experimental, garantindo clareza metodolÃ³gica e separaÃ§Ã£o de responsabilidades entre os sistemas envolvidos.

## ğŸ—ï¸ Arquitetura do Projeto

O projeto completo Ã© composto por trÃªs sistemas independentes:

1. Projeto A â€” Sistema de RH (OLTP)

    - GeraÃ§Ã£o de dados limpos, consistentes e realistas
    
    - NÃ£o aplica Privacidade Diferencial

2. Projeto IntermediÃ¡rio â€” DP Data Pipeline (este repositÃ³rio)

    - ExtraÃ§Ã£o de dados do RH
    
    - AplicaÃ§Ã£o de mecanismos de Privacidade Diferencial
    
    - Versionamento de datasets

3. Projeto B â€” Machine Learning e Ataques de InferÃªncia

    - Consumo dos datasets gerados
    
    - AvaliaÃ§Ã£o de utilidade, vazamento e trade-offs

ğŸ‘‰ Este repositÃ³rio representa exclusivamente a camada de Engenharia de Dados.

## ğŸ¯ Objetivo

Fornecer conjuntos de dados privatizados que permitam avaliar, de forma experimental e reproduzÃ­vel:

  - o impacto da Privacidade Diferencial na utilidade estatÃ­stica dos dados;
  
  - o efeito do ruÃ­do na performance de modelos de Machine Learning;
  
  - a resistÃªncia dos dados a ataques de inferÃªncia e reidentificaÃ§Ã£o.

## âš™ï¸ Responsabilidades do Pipeline

Este sistema Ã© responsÃ¡vel por:

  - Extrair dados estruturados do banco do sistema de RH;
  
  - Selecionar atributos sensÃ­veis e nÃ£o sensÃ­veis;
  
  - Aplicar mecanismos de Privacidade Diferencial com parÃ¢metros configurÃ¡veis (Îµ);
  
  - Gerar mÃºltiplas versÃµes do mesmo dataset (baseline e datasets privatizados);
  
  - Registrar metadados do processo de privatizaÃ§Ã£o;
  
  - Garantir reprodutibilidade dos experimentos.

âŒ O pipeline nÃ£o:

  - treina modelos de Machine Learning;
  
  - executa ataques de inferÃªncia;
  
  - altera o banco de dados de origem.

## ğŸ” Privacidade Diferencial

A Privacidade Diferencial Ã© aplicada como etapa de preparaÃ§Ã£o de dados, antes do uso em Machine Learning.

Mecanismos avaliados podem incluir:

  - Laplace Mechanism
  
  - Gaussian Mechanism
  
  - PerturbaÃ§Ã£o de atributos e/ou labels

Cada execuÃ§Ã£o registra explicitamente:

  - o mecanismo utilizado;
  
  - os valores de Îµ;
  
  - a versÃ£o do dataset gerado.

## ğŸ—‚ï¸ Versionamento de Dados

Os datasets sÃ£o versionados por execuÃ§Ã£o, permitindo comparaÃ§Ãµes entre diferentes estados do sistema de origem.

Exemplo de estrutura:

    datasets/
     â”œâ”€â”€ v1/
     â”‚    â”œâ”€â”€ baseline.csv
     â”‚    â”œâ”€â”€ dp_eps_0.1.csv
     â”‚    â””â”€â”€ dp_eps_1.0.csv
     â”œâ”€â”€ v2/
     â”‚    â”œâ”€â”€ baseline.csv
     â”‚    â”œâ”€â”€ dp_eps_0.1.csv
     â”‚    â””â”€â”€ dp_eps_1.0.csv


Cada versÃ£o representa:

  - um estado especÃ­fico do banco do RH;
  
  - um conjunto fechado e comparÃ¡vel de experimentos.

## ğŸ“¥ Entrada e ğŸ“¤ SaÃ­da de Dados

Entrada

Dados estruturados provenientes do sistema de RH:
  
  - funcionÃ¡rios
  
  - setores
  
  - avaliaÃ§Ãµes
  
  - benefÃ­cios

SaÃ­da
  
  - Dataset original (baseline);
  
  - Datasets privatizados por nÃ­vel de Îµ;
  
  - Metadados da execuÃ§Ã£o (parÃ¢metros, data, versÃ£o).

## â–¶ï¸ ExecuÃ§Ã£o

O pipeline Ã© executado de forma batch e sob demanda.

  - NÃ£o hÃ¡ execuÃ§Ã£o contÃ­nua;
  
  - NÃ£o hÃ¡ dependÃªncia em tempo real entre os sistemas.

MudanÃ§as no sistema de RH nÃ£o afetam automaticamente os experimentos de ML.
Uma nova versÃ£o de dataset sÃ³ Ã© criada quando o pipeline Ã© explicitamente executado.

ğŸ¤– RelaÃ§Ã£o com o Projeto de Machine Learning

O Projeto B consome explicitamente uma versÃ£o definida dos datasets gerados por este pipeline.

Isso garante que os experimentos sejam:

  - reproduzÃ­veis;
  
  - comparÃ¡veis;
  
  - independentes da evoluÃ§Ã£o do sistema de origem.

## ğŸ“ MotivaÃ§Ã£o AcadÃªmica

A separaÃ§Ã£o da camada de Privacidade Diferencial em um sistema independente permite:

  - isolamento da variÃ¡vel experimental;
  
  - rigor metodolÃ³gico;
  
  - alinhamento com boas prÃ¡ticas de engenharia de dados e pesquisa cientÃ­fica.

## â„¹ï¸ ObservaÃ§Ãµes

  - Os dados utilizados sÃ£o simulados e nÃ£o representam indivÃ­duos reais;
  
  - Este projeto Ã© desenvolvido para fins acadÃªmicos e de pesquisa;
  
  - O foco estÃ¡ em clareza experimental, nÃ£o em conveniÃªncia de execuÃ§Ã£o imediata.

## ğŸ“œ LicenÃ§a

Uso acadÃªmico e educacional.

## Nota Final

Este repositÃ³rio nÃ£o existe para â€œfacilitarâ€ o Machine Learning,
ele existe para tornar o experimento correto, reproduzÃ­vel e defensÃ¡vel.

Isso Ã© intencional.
